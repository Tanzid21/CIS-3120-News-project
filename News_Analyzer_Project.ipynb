{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e278ca3",
   "metadata": {},
   "source": [
    "# Project DESCRIPTION:::\n",
    "            \n",
    "***Develop a Python application that uses the New York Times API to fetch recent news articles from a specific section (e.g., Technology, Politics) and analyze the frequency of keywords to identify what subjects are most talked about.\n",
    "Key Features:\n",
    "\n",
    "\n",
    "1.Data Collection:\n",
    "\n",
    "Use the New York Times API to retrieve news articles from selected sections over a certain period of time.\n",
    "Use pandas to extract and store relevant data from articles, such as headlines, publication dates, and keywords.\n",
    "\n",
    "2.Basic Data Analysis:\n",
    "\n",
    "Count the occurrence of unique keywords within the articles to identify the most frequently mentioned topics.\n",
    "Analyze the frequency of words over time to see if interest in certain topics is increasing or decreasing.\n",
    "\n",
    "3.Data Visualization:\n",
    "\n",
    "Use Matplotlib and Seaborn to create simple visualizations:\n",
    "Bar chart showing the top 10 most frequently mentioned keywords in the news section.\n",
    "Line graph illustrating the number of articles published per day or week to spot trends over the selected period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests pandas\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f298e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6928a121",
   "metadata": {},
   "source": [
    "# Data Collection::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6851bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf01f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we need to select one specific section, I have choosed world section.\n",
    "# From NY Times, I subsitutute the link with the specific link in Top stories section from NY Time\n",
    "top_stories=r.get(f\"https://api.nytimes.com/svc/topstories/v2/world.json?api-key={API_KEY}\").content.decode()\n",
    "nyt_home = pd.read_json(StringIO(top_stories))\n",
    "nyt_home\n",
    "results = pd.json_normalize(nyt_home['results'])\n",
    "results\n",
    "keywords = results['des_facet'].explode()\n",
    "keywords = keywords.value_counts()\n",
    "print(keywords)\n",
    "keywords = keywords.reset_index()\n",
    "\n",
    "keywords\n",
    "\n",
    "# Create our chart\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(10, 50))\n",
    "plt.xticks(range(min(keywords['des_facet']),max(keywords['des_facet'])))\n",
    "sns.barplot(x='des_facet', y='index', data=keywords, ci=None)\n",
    "\n",
    "plt.title('Keyword Frequencies')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Keyword')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66cbd82c",
   "metadata": {},
   "source": [
    "QUESTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = r.get(f\"https://api.nytimes.com/svc/topstories/v2/world.json?api-key={API_KEY}\")\n",
    "top_stories = response.json()\n",
    "\n",
    "# Normalize the JSON response to extract 'results' into a DataFrame\n",
    "results_df = pd.json_normalize(top_stories['results'])\n",
    "\n",
    "# Display the relevant columns to ensure the data is loaded correctly\n",
    "print(results_df[['title', 'published_date', 'des_facet']].head())\n",
    "\n",
    "# Assuming each story can have multiple keywords and they are in 'des_facet', process these for easier analysis\n",
    "# First,extracting and displaying headlines, publication dates directly, and keywords separately\n",
    "\n",
    "# Extract headlines and publication dates directly\n",
    "headlines = results_df['title']\n",
    "pub_dates = results_df['published_date']\n",
    "\n",
    "# Keywords ('des_facet') might need processing if they are nested lists\n",
    "# Ensure it's a list for each row; if it's not, convert it\n",
    "keywords = results_df['des_facet'].apply(lambda x: x if isinstance(x, list) else [x])##from chatGPT\n",
    "\n",
    "print(\"\\nSample Headlines:\\n\", headlines.head())\n",
    "print(\"\\nSample Publication Dates:\\n\", pub_dates.head())\n",
    "print(\"\\nSample Keywords:\\n\", keywords.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d21a6",
   "metadata": {},
   "source": [
    "# DATA  ANAYSIS"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d146202a",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce22cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you've already fetched the top stories into `top_stories_response`\n",
    "API_KEY = \"4tr4oLn5GgA7ATVLOVG5sDU2MT40rmup\"\n",
    "top_stories_response = requests.get(f\"https://api.nytimes.com/svc/topstories/v2/world.json?api-key={API_KEY}\")\n",
    "top_stories = top_stories_response.content.decode()\n",
    "\n",
    "# Assuming 'keywords' is a Series of lists from the 'des_facet' column\n",
    "all_keywords = keywords.explode()  # Flatten the list\n",
    "keyword_counts = all_keywords.value_counts()  # Count occurrences\n",
    "print(\"Most Frequently Mentioned Topics:\")\n",
    "print(keyword_counts.head(10))  # Display top 10\n",
    "\n",
    "# Create a DataFrame where each keyword is associated with a publication date\n",
    "keywords_with_dates = results_df[['published_date', 'des_facet']].explode('des_facet')\n",
    "keywords_with_dates['published_date'] = pd.to_datetime(keywords_with_dates['published_date']).dt.to_period('M')  # Convert dates to months\n",
    "\n",
    "# Count occurrences of each keyword by month\n",
    "keywords_frequency_over_time = keywords_with_dates.groupby(['published_date', 'des_facet']).size().unstack(fill_value=0)\n",
    "\n",
    "print(keywords_frequency_over_time.head())\n",
    "\n",
    "# Continue with keyword frequency analysis and visualization as before\n",
    "keywords = results['des_facet'].explode()\n",
    "keywords_count = keywords.value_counts().reset_index()\n",
    "keywords_count.columns = ['Keyword', 'Frequency']\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Frequency', y='Keyword', data=keywords_count.head(10), ci=None)\n",
    "plt.title('Top Keywords Frequencies')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Keyword')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2d217",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4594d9ae",
   "metadata": {},
   "source": [
    "# Quation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91032149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import API_KEY\n",
    "\n",
    "# Fetch the top stories\n",
    "top_stories_response = requests.get(f\"https://api.nytimes.com/svc/topstories/v2/world.json?api-key={API_KEY}\")\n",
    "top_stories = top_stories_response.content.decode()\n",
    "\n",
    "# Convert the fetched data into a pandas DataFrame\n",
    "nyt_home = pd.read_json(StringIO(top_stories))\n",
    "results = pd.json_normalize(nyt_home['results'])\n",
    "\n",
    "# Explode and count keywords\n",
    "keywords = results['des_facet'].explode()\n",
    "keywords_count = keywords.value_counts().reset_index()\n",
    "keywords_count.columns = ['Keyword', 'Frequency']\n",
    "\n",
    "# Create the chart\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Frequency', y='Keyword', data=keywords_count.head(10), ci=None) \n",
    "plt.title('Top Keywords Frequencies')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Keyword')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55973065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
